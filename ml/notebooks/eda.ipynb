{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ae83973",
   "metadata": {},
   "source": [
    "# Executive EDA for CareerLens Datasets\n",
    "\n",
    "This notebook performs a high-level Exploratory Data Analysis (EDA) on the datasets loaded from the `data_catalog`. The goal is to quickly assess data quality, identify potential features and targets, and generate a concise action plan for preprocessing and feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84388851",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the project root to the Python path to allow importing from ml.pipelines\n",
    "project_root = Path().resolve().parents[1]\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n",
    "\n",
    "from ml.pipelines.data_catalog import load_all_datasets\n",
    "\n",
    "# Load all datasets from the catalog\n",
    "datasets = load_all_datasets()\n",
    "\n",
    "print(f\"Loaded {len(datasets)} datasets: {', '.join(datasets.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168d01c3",
   "metadata": {},
   "source": [
    "## Analysis Functions\n",
    "\n",
    "Helper functions to perform the EDA steps for each dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d9df6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Any, List\n",
    "\n",
    "def analyze_dataframe(df_name: str, df: pd.DataFrame) -> Dict[str, Any]:\n",
    "    \"\"\"Performs a comprehensive EDA on a given DataFrame.\"\"\"\n",
    "    \n",
    "    report = {\n",
    "        \"name\": df_name,\n",
    "        \"shape\": df.shape,\n",
    "        \"duplicates\": df.duplicated().sum(),\n",
    "        \"columns\": []\n",
    "    }\n",
    "    \n",
    "    total_rows = len(df)\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_report = {}\n",
    "        \n",
    "        # Column Types and Missing %\n",
    "        col_report['type'] = str(df[col].dtype)\n",
    "        missing_count = df[col].isnull().sum()\n",
    "        col_report['missing_pct'] = round((missing_count / total_rows) * 100, 2) if total_rows > 0 else 0\n",
    "\n",
    "        # Obvious Label/Target Columns\n",
    "        if 'career' in col.lower() or 'path' in col.lower() or 'role' in col.lower() or 'title' in col.lower():\n",
    "            col_report['is_potential_target'] = True\n",
    "        else:\n",
    "            col_report['is_potential_target'] = False\n",
    "\n",
    "        # Categorical Cardinality\n",
    "        if df[col].dtype == 'object' or pd.api.types.is_categorical_dtype(df[col]):\n",
    "            col_report['cardinality'] = df[col].nunique()\n",
    "\n",
    "        # Numeric Outliers\n",
    "        if pd.api.types.is_numeric_dtype(df[col]):\n",
    "            col_report['stats'] = df[col].describe().to_dict()\n",
    "            q1 = df[col].quantile(0.25)\n",
    "            q3 = df[col].quantile(0.75)\n",
    "            iqr = q3 - q1\n",
    "            lower_bound = q1 - 1.5 * iqr\n",
    "            upper_bound = q3 + 1.5 * iqr\n",
    "            outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
    "            col_report['outlier_count'] = len(outliers)\n",
    "\n",
    "        report['columns'].append({col: col_report})\n",
    "        \n",
    "    return report\n",
    "\n",
    "def generate_summary_markdown(report: Dict[str, Any]) -> str:\n",
    "    \"\"\"Generates a markdown summary from the analysis report.\"\"\"\n",
    "    \n",
    "    markdown = f\"### Dataset: `{report['name']}`\\n\\n\"\n",
    "    markdown += f\"- **Shape**: {report['shape'][0]} rows, {report['shape'][1]} columns\\n\"\n",
    "    markdown += f\"- **Duplicates**: {report['duplicates']} rows\\n\\n\"\n",
    "    \n",
    "    keep = []\n",
    "    drop = []\n",
    "    impute = []\n",
    "    engineer = []\n",
    "    \n",
    "    markdown += \"| Column | Type | Missing % | Cardinality | Outliers | Notes |\\n\"\n",
    "    markdown += \"|--------|------|-----------|-------------|----------|-------|\\n\"\n",
    "    \n",
    "    for col_data in report['columns']:\n",
    "        for col_name, col_report in col_data.items():\n",
    "            cardinality = col_report.get('cardinality', 'N/A')\n",
    "            outliers = col_report.get('outlier_count', 'N/A')\n",
    "            notes = []\n",
    "            \n",
    "            if col_report.get('is_potential_target'):\n",
    "                notes.append(\"Potential target.\")\n",
    "                engineer.append(f\"`{col_name}` (as target)\")\n",
    "\n",
    "            if col_report['missing_pct'] > 50:\n",
    "                notes.append(\"High missing %.\")\n",
    "                drop.append(f\"`{col_name}`\")\n",
    "            elif col_report['missing_pct'] > 0:\n",
    "                notes.append(\"Needs imputation.\")\n",
    "                impute.append(f\"`{col_name}`\")\n",
    "            \n",
    "            if isinstance(cardinality, int) and cardinality > 50 and not col_report.get('is_potential_target'):\n",
    "                notes.append(\"High cardinality.\")\n",
    "                engineer.append(f\"`{col_name}` (embedding/grouping)\")\n",
    "\n",
    "            if isinstance(outliers, int) and outliers > 0:\n",
    "                notes.append(f\"{outliers} outliers detected.\")\n",
    "\n",
    "            if not notes:\n",
    "                notes.append(\"Looks good.\")\n",
    "                keep.append(f\"`{col_name}`\")\n",
    "\n",
    "            markdown += f\"| `{col_name}` | {col_report['type']} | {col_report['missing_pct']}% | {cardinality} | {outliers} | {' '.join(notes)} |\\n\"\n",
    "\n",
    "    markdown += \"\\n#### Recommendations:\\n\"\n",
    "    markdown += f\"- **Keep**: {', '.join(keep)}\\n\"\n",
    "    markdown += f\"- **Drop**: {', '.join(drop)}\\n\"\n",
    "    markdown += f\"- **Impute**: {', '.join(impute)}\\n\"\n",
    "    markdown += f\"- **Engineer**: {', '.join(engineer)}\\n\"\n",
    "    \n",
    "    markdown += \"\\n#### Hypotheses:\\n\"\n",
    "    markdown += \"- **Career Path**: Potential target columns seem to be related to job titles. These can be cleaned and used as labels.\\n\"\n",
    "    markdown += \"- **Skills**: Columns with high cardinality text might contain skill descriptions. These can be processed with TF-IDF or embeddings to create a skills feature set.\\n\"\n",
    "\n",
    "    return markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b336f7a",
   "metadata": {},
   "source": [
    "## Run Analysis and Generate Reports\n",
    "\n",
    "Iterate through each loaded dataset, perform the EDA, and display the summary report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4731559a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "for name, df in datasets.items():\n",
    "    analysis_report = analyze_dataframe(name, df)\n",
    "    markdown_summary = generate_summary_markdown(analysis_report)\n",
    "    display(Markdown(markdown_summary))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
